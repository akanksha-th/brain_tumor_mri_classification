{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d36f63d",
      "metadata": {
        "id": "1d36f63d"
      },
      "outputs": [],
      "source": [
        "import os, math, numpy as np, random, time\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4032da46",
      "metadata": {
        "id": "4032da46",
        "outputId": "0df2ca7c-c990-42f2-ec58-ade54853d401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version: 2.7.1+cpu\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "print(f'Torch version: {torch.__version__}')\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae16edf",
      "metadata": {
        "id": "dae16edf"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    ]),\n",
        "\n",
        "    # Just normalization for validation\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(150),\n",
        "        transforms.CenterCrop(150),\n",
        "        transforms.ToTensor(),\n",
        "\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f95f48f",
      "metadata": {
        "id": "1f95f48f",
        "outputId": "12bbaede-8e05-4711-f06b-9ea2de655570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['glioma', 'meningioma', 'no_tumor', 'pituitary']\n",
            "Dataset sizes: {'train': 1695, 'valid': 502}\n",
            "Number of training batches: 212\n",
            "Number of validation batches: 63\n"
          ]
        }
      ],
      "source": [
        "data_dir = os.path.join('..', '.data')\n",
        "\n",
        "image_dataset = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "               for x in ['train', 'valid']}\n",
        "dataloaders = {x: DataLoader(image_dataset[x], batch_size=8, shuffle=True, num_workers=2, persistent_workers=True)\n",
        "               for x in ['train', 'valid']}\n",
        "\n",
        "dataset_sizes = {x: len(image_dataset[x]) for x in ['train', 'valid']}\n",
        "class_names = image_dataset['train'].classes\n",
        "\n",
        "print(f'Classes: {class_names}')\n",
        "print(f'Dataset sizes: {dataset_sizes}')\n",
        "print(f'Number of training batches: {dataloaders[\"train\"].__len__()}')\n",
        "print(f'Number of validation batches: {dataloaders[\"valid\"].__len__()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1823423b",
      "metadata": {
        "id": "1823423b",
        "outputId": "8f050eda-8b05-49f2-a7d9-a72b66d0ee2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input batch shape: torch.Size([8, 3, 150, 150])\n"
          ]
        }
      ],
      "source": [
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "print(f'Input batch shape: {inputs.size()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fba728",
      "metadata": {
        "id": "73fba728"
      },
      "outputs": [],
      "source": [
        "class SepConv2d(nn.Module):\n",
        "    \"\"\"Separable Convolution = Depthwise Convolution + Pointwise Convolution\"\"\"\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False):\n",
        "        super().__init__()\n",
        "        self.depth = nn.Conv2d(in_ch, in_ch, kernel_size=kernel_size, stride=stride,\n",
        "                               padding=padding, groups=in_ch, bias=bias)\n",
        "        self.point = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depth(x)\n",
        "        x = self.point(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation Block\"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super().__init__()\n",
        "        reduced = max(1, channels // reduction)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(channels, reduced)\n",
        "        self.fc2 = nn.Linear(reduced, channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.pool(x).view(b, c)\n",
        "        y = torch.relu(self.fc1(y))\n",
        "        y = torch.sigmoid(self.fc2(y)).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"ConvBlock: SepConv -> BN -> MaxPool -> SEBlock\"\"\"\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            SepConv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            SEBlock(out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.seq(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38bdd226",
      "metadata": {
        "id": "38bdd226",
        "outputId": "30081237-d578-4063-c473-3eec6efbc9cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total params: 39629\n",
            "Total Trainable Parameters: 39629\n",
            "out shape: torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "class LightCNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.block1 = ConvBlock(in_channels, 32)\n",
        "        self.block2 = ConvBlock(32, 64)\n",
        "        self.block3 = ConvBlock(64, 128)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(128, 128)\n",
        "        self.drop1 = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.drop2 = nn.Dropout(0.4)\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.drop1(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.drop2(x)\n",
        "        logits = self.fc3(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "model = LightCNN(in_channels=3, num_classes=len(class_names)).to(device)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total params: {total_params}\\nTotal Trainable Parameters: {trainable_params}\")\n",
        "\n",
        "x = torch.randn(2,3,150,150)\n",
        "y = model(x)\n",
        "print(\"out shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "059a0803",
      "metadata": {
        "id": "059a0803"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac079c9",
      "metadata": {
        "id": "2ac079c9"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    pbar = tqdm(dataloader, desc='train', leave=False)\n",
        "    for inputs, labels in pbar:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = running_corrects / len(dataloader.dataset)\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate_one_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(dataloader, desc='valid', leave=False)\n",
        "        for inputs, labels in pbar:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).item()\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = running_corrects / len(dataloader.dataset)\n",
        "    return epoch_loss, epoch_acc, all_preds, all_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "487b120c",
      "metadata": {
        "id": "487b120c",
        "outputId": "2b49a2ce-065d-442e-8e0e-e4599dbd0787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                              \r"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'Tensor' object has no attribute 'items'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     val_loss, val_acc, val_preds, val_labels \u001b[38;5;241m=\u001b[39m validate_one_epoch(model, dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m], criterion, device)\n\u001b[0;32m     12\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
            "Cell \u001b[1;32mIn[15], line 18\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     17\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m running_corrects \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     20\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'items'"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 25\n",
        "best_val_acc = 0.0\n",
        "best_model_path = 'best_custom_model.pth'\n",
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    train_loss, train_acc = train_one_epoch(model, dataloaders['train'], criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_preds, val_labels = validate_one_epoch(model, dataloaders['valid'], criterion, device)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    print(f\"    train_loss: {train_loss:.4f}    train_acc: {train_acc:.4f}\")\n",
        "    print(f\"    val_loss: {val_loss:.4f}    val_acc: {val_acc:.4f}\")\n",
        "\n",
        "    # save best\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state': model.state_dict(),\n",
        "            'optimizer_state': optimizer.state_dict(),\n",
        "            'val_acc': val_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'class_names': class_names\n",
        "        }, best_model_path)\n",
        "        print(f\"Saved new best model\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f\"Training Complete in {total_time/60:.2f} minutes. Best val acc: {best_val_acc:.4f}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab9067b6",
      "metadata": {
        "id": "ab9067b6"
      },
      "outputs": [],
      "source": [
        "ckpt = torch.load(best_model_path, map_location=device)\n",
        "model.load_state_dict(ckpt['model_state'])\n",
        "model.to(device)\n",
        "\n",
        "val_loss, val_acc, val_preds, val_labels = validate_one_epoch(model, dataloaders['valid'], criterion, device)\n",
        "print('Final validation loss: {:.4f}, acc: {:.4f}'.format(val_loss, val_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00508025",
      "metadata": {
        "id": "00508025"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(val_labels, val_preds)\n",
        "print(F\"Confusion Matrix:\\n {cm}\")\n",
        "print(\"Classification Report:\\n\", classification_report(val_labels, val_preds, target_names=classes, digits=4))\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1,2,1); plt.plot(history['train_loss'], labels='train'); plt.plot(history['val_loss'], labels='val'); plt.title(\"Loss\"); plt.legend()\n",
        "plt.subplot(1,2,2); plt.plot(history['train_acc'], labels='train'); plt.plot(history['val_acc'], labels='val'); plt.title(\"Accuracy\"); plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}